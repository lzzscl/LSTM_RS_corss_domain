{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = os.open('...',os.O_RDONLY)\n",
    "files = os.listdir(work_path)\n",
    "files= sorted(files)\n",
    "files = files[1:]\n",
    "end_bid = files.index('...')\n",
    "files = files[:end_bid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu_vec = []\n",
    "time_step = 0\n",
    "for file in files:\n",
    "    vu_vec.append(np.load('...' + file).item())\n",
    "    time_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order = pd.read_csv('...', sep = '\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deal_vec = pd.read_csv('...', compression='gzip')\n",
    "df_deal_vec.dealvec = df_deal_vec.dealvec.map(lambda x: x[2:-2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order['ins_tm'] = pd.to_datetime(df_order['ins_tm'],format='%Y-%m-%d %H:%M:%S')\n",
    "df_order['date'] = df_order.ins_tm.dt.date\n",
    "train_order = df_order.loc[df_order.date <= datetime.date(2017,6,18)]\n",
    "train_order = train_order.loc[df_order.date >= datetime.date(2017,6,12)]\n",
    "train_order = train_order[['account_id','deal_id']]\n",
    "train_order['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_order = df_order.loc[df_order.date == datetime.date(2017,6,19)]\n",
    "dev_order = test_order[['account_id','deal_id']]\n",
    "dev_order['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_order = df_order.loc[df_order.date == datetime.date(2017,6,20)]\n",
    "test_order = test_order[['account_id','deal_id']]\n",
    "test_order['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/39322finished!\n",
      "10000/39322finished!\n",
      "20000/39322finished!\n",
      "30000/39322finished!\n"
     ]
    }
   ],
   "source": [
    "item_list = list(train_order.deal_id.unique())\n",
    "user_list = list(train_order.account_id.unique())\n",
    "\n",
    "num_epo = 0\n",
    "Negative_sample = []\n",
    "for user in user_list:\n",
    "    bought_list = list(train_order[train_order.account_id == user].deal_id.values)\n",
    "    negative_list = list(set(item_list)^set(bought_list))\n",
    "    some = random.sample(negative_list, len(bought_list))\n",
    "    for i in range(len(bought_list)):\n",
    "        Negative_sample.append([user, some[i], 0])\n",
    "    if num_epo%10000 == 0:\n",
    "        print(str(num_epo) + '/' + str(len(user_list)) + 'finished!')\n",
    "    num_epo += 1\n",
    "df_Ns = pd.DataFrame(Negative_sample, columns=['account_id', 'deal_id', 'rating'])\n",
    "train_order = train_order.append(df_Ns, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5317finished!\n"
     ]
    }
   ],
   "source": [
    "item_list = list(dev_order.deal_id.unique())\n",
    "user_list = list(dev_order.account_id.unique())\n",
    "\n",
    "num_epo = 0\n",
    "Negative_sample = []\n",
    "for user in user_list:\n",
    "    bought_list = list(dev_order[dev_order.account_id == user].deal_id.values)\n",
    "    negative_list = list(set(item_list)-set(bought_list))\n",
    "    some = random.sample(negative_list, len(set(bought_list)&set(item_list)))\n",
    "    for i in range(len(set(bought_list)&set(item_list))):\n",
    "        Negative_sample.append([user, some[i], 0])\n",
    "    if num_epo%10000 == 0:\n",
    "        print(str(num_epo) + '/' + str(len(user_list)) + 'finished!')\n",
    "    num_epo += 1\n",
    "df_Ns = pd.DataFrame(Negative_sample, columns=['account_id', 'deal_id', 'rating'])\n",
    "dev_order = dev_order.append(df_Ns, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/4412finished!\n"
     ]
    }
   ],
   "source": [
    "item_list = list(test_order.deal_id.unique())\n",
    "user_list = list(test_order.account_id.unique())\n",
    "\n",
    "num_epo = 0\n",
    "Negative_sample = []\n",
    "for user in user_list:\n",
    "    bought_list = list(test_order[test_order.account_id == user].deal_id.values)\n",
    "    negative_list = list(set(item_list)-set(bought_list))\n",
    "    some = random.sample(negative_list, len(set(bought_list)&set(item_list)))\n",
    "    for i in range(len(set(bought_list)&set(item_list))):\n",
    "        Negative_sample.append([user, some[i], 0])\n",
    "    if num_epo%10000 == 0:\n",
    "        print(str(num_epo) + '/' + str(len(user_list)) + 'finished!')\n",
    "    num_epo += 1\n",
    "df_Ns = pd.DataFrame(Negative_sample, columns=['account_id', 'deal_id', 'rating'])\n",
    "test_order = test_order.append(df_Ns, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, dev = train_test_split(train_order, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeID2vec(i,user_id):\n",
    "    num_empty = 0\n",
    "    try:\n",
    "        user_vec = vu_vec[i][user_id]\n",
    "    except:\n",
    "        #user_vec = np.zeros([1,200], dtype = float)\n",
    "        user_vec = []\n",
    "        num_empty = 1\n",
    "    return user_vec, num_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, valid_day):\n",
    "    # generate input feature of user_vec and item_vec\n",
    "    user_list = [] # train.account_id.values\n",
    "    item_list = [] # train.deal_id.values\n",
    "    label = df.rating.values\n",
    "    num_empty = []\n",
    "\n",
    "    for user_id in df.account_id.values:\n",
    "        temp_vec = []\n",
    "        emp_num = 0\n",
    "        for i in range(time_step):\n",
    "            user_vec, emt = changeID2vec(i,user_id)\n",
    "            temp_vec.extend(user_vec)\n",
    "            emp_num += emt\n",
    "        for i in range(emp_num):\n",
    "            temp_vec.extend(np.zeros([1,200], dtype = float))\n",
    "        user_list.append(temp_vec)\n",
    "        num_empty.append(emp_num)\n",
    "\n",
    "    for item_id in df.deal_id.values:\n",
    "        item_list.extend(df_deal_vec.loc[df_deal_vec.deal_id == item_id]['dealvec'].values) \n",
    "\n",
    "    useful_index = []\n",
    "    for i in range(len(num_empty)):\n",
    "        if(num_empty[i] <= time_step-valid_day):\n",
    "            useful_index.extend([i])\n",
    "\n",
    "    useful_user_list = []\n",
    "    useful_item_list = []\n",
    "    useful_label_list = []\n",
    "    for index in useful_index:\n",
    "        useful_user_list.append(user_list[index])\n",
    "        useful_item_list.append(item_list[index])\n",
    "        useful_label_list.append(label[index])\n",
    "\n",
    "    useful_user = np.array(useful_user_list)\n",
    "    useful_item = np.array(useful_item_list)\n",
    "    useful_label = np.array(useful_label_list)\n",
    "    \n",
    "    return useful_user, useful_item, useful_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user, train_item, train_label = preprocess(train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_user, train_dev_item, train_dev_label = preprocess(dev,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_user, dev_item, dev_label = preprocess(dev_order, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user, test_item, test_label = preprocess(test_order, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bi-LSTM with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined shared layers\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(12, activation='tanh')\n",
    "densor2 = Dense(1, activation='relu')\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes=1)\n",
    "\n",
    "Norm_user = BatchNormalization()\n",
    "Norm_item = BatchNormalization()\n",
    "\n",
    "densor_user1 = Dense(128, activation='relu')\n",
    "densor_deal1 = Dense(128, activation='relu')\n",
    "densor_user2 = Dense(128, activation='relu')\n",
    "densor_deal2 = Dense(128, activation='relu')\n",
    "densor_user3 = Dense(64, activation='relu')\n",
    "densor_deal3 = Dense(64, activation='relu')\n",
    "densor_user4 = Dense(32, activation='relu')\n",
    "densor_deal4 = Dense(32, activation='relu')\n",
    "\n",
    "flat = Flatten()\n",
    "concat = Dot(axes=1)\n",
    "output = Dense(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a):\n",
    "    e = densor1(a)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas, a])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generate(Tx, n_a, vec_dim):\n",
    "    X_user = Input(shape=(Tx, vec_dim))\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a, return_sequences= True))(X_user)\n",
    "    context = one_step_attention(a)\n",
    "    \n",
    "    X_deal = Input(shape=(vec_dim,))\n",
    "     \n",
    "    flat_user = flat(context)\n",
    "    \n",
    "    user_0 = Norm_user(flat_user)\n",
    "    deal_0 = Norm_item(X_deal)\n",
    "    user_1 = densor_user1(user_0)\n",
    "    deal_1 = densor_deal1(deal_0)\n",
    "    user_2 = densor_user2(user_1)\n",
    "    deal_2 = densor_deal2(deal_1)\n",
    "    user_3 = densor_user3(user_2)\n",
    "    deal_3 = densor_deal3(deal_2)\n",
    "    user_4 = densor_user4(user_3)\n",
    "    deal_4 = densor_deal4(deal_3)\n",
    "    \n",
    "    hidden = concat([user_4, deal_4])\n",
    "    pred = output(hidden)\n",
    "    \n",
    "    model = Model(input = [X_user, X_deal], outputs = pred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmde-lab/anaconda3/envs/whxPyEnv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model = model_generate(time_step, 256, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, 32, 200)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 32, 512)      935936      input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 32, 12)       6156        bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 32, 1)        13          dense_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 32, 1)        0           dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 1, 512)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 512)          0           dot_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512)          2048        flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 200)          800         input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 128)          65664       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 128)          25728       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 128)          16512       dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 128)          16512       dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 64)           8256        dense_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 64)           8256        dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 32)           2080        dense_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_164 (Dense)               (None, 32)           2080        dense_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 1)            0           dense_163[0][0]                  \n",
      "                                                                 dense_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_165 (Dense)               (None, 1)            2           dot_30[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,090,043\n",
      "Trainable params: 1,088,619\n",
      "Non-trainable params: 1,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21010 samples, validate on 1108 samples\n",
      "Epoch 1/100\n",
      "21010/21010 [==============================] - 35s 2ms/step - loss: 0.6037 - acc: 0.7188 - val_loss: 0.5277 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52766, saving model to model.hdf5\n",
      "Epoch 2/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.5280 - acc: 0.7762 - val_loss: 0.5001 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52766 to 0.50008, saving model to model.hdf5\n",
      "Epoch 3/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.4958 - acc: 0.7909 - val_loss: 0.4685 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50008 to 0.46849, saving model to model.hdf5\n",
      "Epoch 4/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.4645 - acc: 0.8066 - val_loss: 0.4446 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46849 to 0.44456, saving model to model.hdf5\n",
      "Epoch 5/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.4403 - acc: 0.8165 - val_loss: 0.4377 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44456 to 0.43769, saving model to model.hdf5\n",
      "Epoch 6/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.4185 - acc: 0.8236 - val_loss: 0.4229 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43769 to 0.42287, saving model to model.hdf5\n",
      "Epoch 7/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3983 - acc: 0.8332 - val_loss: 0.4171 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42287 to 0.41706, saving model to model.hdf5\n",
      "Epoch 8/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3831 - acc: 0.8399 - val_loss: 0.4124 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41706 to 0.41243, saving model to model.hdf5\n",
      "Epoch 9/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3656 - acc: 0.8483 - val_loss: 0.4104 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41243 to 0.41040, saving model to model.hdf5\n",
      "Epoch 10/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3475 - acc: 0.8576 - val_loss: 0.4149 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41040\n",
      "Epoch 11/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3380 - acc: 0.8638 - val_loss: 0.4096 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41040 to 0.40957, saving model to model.hdf5\n",
      "Epoch 12/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3181 - acc: 0.8746 - val_loss: 0.4130 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40957\n",
      "Epoch 13/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.3088 - acc: 0.8754 - val_loss: 0.4153 - val_acc: 0.8312\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40957\n",
      "Epoch 14/100\n",
      "21010/21010 [==============================] - 28s 1ms/step - loss: 0.2971 - acc: 0.8860 - val_loss: 0.4361 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40957\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "check_point = ModelCheckpoint('model.hdf5', verbose=True, save_best_only = True)\n",
    "early_stop = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "opt = model.compile(optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.001),\n",
    "                   metrics = ['accuracy'],\n",
    "                   loss = binary_crossentropy)\n",
    "history = model.fit([train_user, train_item], train_label,\n",
    "          validation_data= ([train_dev_user, train_dev_item], train_dev_label),\n",
    "          epochs=100,\n",
    "          batch_size=32,\n",
    "          verbose=True,\n",
    "          callbacks=[early_stop, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8fa8717e80>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(df_user, df_item):\n",
    "    pred_result = model.predict([df_user, df_item])\n",
    "    return pred_result\n",
    "def new_print_result(df_user, df_item, df_label):\n",
    "    pred_result = model_pred(df_user, df_item)\n",
    "    for i in range(len(pred_result)):\n",
    "        pred_result[i] = int(pred_result[i][0] >= 0.5)\n",
    "    print((pred_result == 1).sum())\n",
    "    print('accuracy: ',  accuracy_score(df_label, pred_result))\n",
    "    print(classification_report(df_label, pred_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n",
      "accuracy:  0.8240072202166066\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.80      0.82       561\n",
      "          1       0.80      0.85      0.83       547\n",
      "\n",
      "avg / total       0.83      0.82      0.82      1108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_print_result(train_dev_user, train_dev_item, train_dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589\n",
      "accuracy:  0.6862680683311432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.67      0.68      1510\n",
      "          1       0.68      0.71      0.69      1534\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_print_result(test_user, test_item, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21010"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "lizhi",
   "language": "python",
   "name": "lizhi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
